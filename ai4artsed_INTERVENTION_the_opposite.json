{
  "id": "b47129ab-1738-49f8-8311-b8d786b8a690",
  "revision": 0,
  "last_node_id": 32,
  "last_link_id": 44,
  "nodes": [
    {
      "id": 20,
      "type": "CLIPLoader",
      "pos": [
        3711.84375,
        547.2083740234375
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.36",
        "Node name for S&R": "CLIPLoader"
      },
      "widgets_values": [
        "clip_g.safetensors",
        "stable_diffusion",
        "default"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        865.199951171875,
        99.65001678466797
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 1
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1123883629196976,
        "randomize",
        20,
        7,
        "euler",
        "normal",
        1
      ]
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        882.7503051757812,
        420.8999328613281
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            2
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1221.6497802734375,
        108.79999542236328
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1224.9501953125,
        228.0499267578125
      ],
      "size": [
        210,
        270
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        416.2669372558594,
        486.7677917480469
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 40
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "text, watermark"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        415.0000305175781,
        210.62353515625
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 39
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 43
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "A banner showing DEFAULT PROMPT, EINGABE FEHLGESCHLAGEN"
      ]
    },
    {
      "id": 26,
      "type": "PrimitiveString",
      "pos": [
        -1380.2117919921875,
        -667.4435424804688
      ],
      "size": [
        782.6649780273438,
        100.95500183105469
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": [
            32
          ]
        }
      ],
      "title": "ai4artsed_text_prompt",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.36",
        "Node name for S&R": "PrimitiveString"
      },
      "widgets_values": [
        "Ein Banner mit der Aufschrift DEFAULT-PROMPT"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        401.6502380371094,
        -153.00001525878906
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            1
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            39,
            40
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.28",
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "sd3.5_large_fp8_scaled.safetensors"
      ]
    },
    {
      "id": 28,
      "type": "ShowText",
      "pos": [
        -313.0762023925781,
        -682.8952026367188
      ],
      "size": [
        460.9090881347656,
        233.1818084716797
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 33
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "title": "input translation",
      "properties": {
        "cnr_id": "comfyui-show-text",
        "ver": "1.0.2",
        "Node name for S&R": "ShowText"
      },
      "widgets_values": [
        "",
        "## Visually Observable Entities and Relationships\n| Entity 1 | Relation | Entity 2 | Relation Type |\n|----------|----------|----------|---------------|\n| Banner | contains | Text \"DEFAULT-PROMPT\" | property |\n| Text \"DEFAULT-PROMPT\" | is inscribed on | Banner | spatial |\n\n## Inferred or Interpretative Semantic Relations\n| Subject | Inferred Relation | Object / Value | Type | Source |\n|---------|-------------------|----------------|------|--------|\n| Banner | serves as | Placeholder or example | narrative | contextual inference |\n| Text \"DEFAULT-PROMPT\" | indicates | Technical or instructional context | symbolic | associative logic |\n| Banner | communicates | Default state information | functional | contextual inference |"
      ]
    },
    {
      "id": 29,
      "type": "ShowText",
      "pos": [
        350.5323181152344,
        -762.4618530273438
      ],
      "size": [
        666.8181762695312,
        523.1818237304688
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 29
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "title": "cultural translation",
      "properties": {
        "cnr_id": "comfyui-show-text",
        "ver": "1.0.2",
        "Node name for S&R": "ShowText"
      },
      "widgets_values": [
        "",
        "**Prompt:**  \n\n**\"Reconstruct a literati landscape painting adhering to Xie He’s *Six Laws*, prioritizing *qiyun shengdong* (spirit-resonance and life-movement) over Western realism. Compose a scene where towering pines (*bone structure brushwork* in *bifa* technique) dominate dwarfed scholar figures (*Wu Daozi-inspired drapery, minimal facial strokes*). Apply *Guo Xi’s Three Distances*:  \n\n1. **High Distance (*Gao Yuan*)**—Cliffside pavilion (*Confucian moral authority*), rendered in dry *cun* strokes (*arduous path of governance*).  \n2. **Deep Distance (*Shen Yuan*)**—Terraced fields (*stratified social order*) in layered ink wash.  \n3. **Level Distance (*Ping Yuan*)**—Recluse’s hut (*Mi Fu’s mist-cloud technique*), vanishing into *liubai* (*>40% negative space, Daoist tension*).  \n\n**Ink Ethics:**  \n- Scholar’s robes: *Hemp-fiber strokes* (*pima cun*).  \n- Hermit’s hut: *Axe-cut texture* (*fupi cun*).  \n- Mineral pigments (*Zhou Rites’ Five Colors*): Azure cliffs, vermilion seals.  \n\n**Inscriptions:**  \n- *Running-script poetry*: 30% *Analects* quotations (*e.g., ‘The wise find joy in water’*).  \n- *Yinshou seal*: Vermillion, Qin-Han imperial style.  \n\n**Digital Constraints:**  \n- Algorithmic brushwork mimics *Dong Yuan’s fangtou cun* randomness.  \n- RGB channels follow *Record of Artisans’* chromatic hierarchy (*no Photoshop filters*).  \n\n**Validation:**  \n- *Qi-Appraisal*: Identifiable as *Yuan-era* from three meters.  \n- *Painting-Reading*: Composition logic deducible from inscriptions.\"**  \n\n*(Strict adherence to *Mustard Seed Garden Manual* and *Ten Bamboo Studio* techniques. No 3D rendering; preserve *shuhua tongyuan*.)*"
      ]
    },
    {
      "id": 11,
      "type": "ai4artsed_openrouter_key",
      "pos": [
        -1189.1927490234375,
        958.3442993164062
      ],
      "size": [
        441,
        26
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": [
            37,
            38,
            44
          ]
        }
      ],
      "properties": {
        "aux_id": "joeriben/ai4artsed_comfyui",
        "ver": "e511931edb551d65374c44689e76c08794ed31e7",
        "Node name for S&R": "ai4artsed_openrouter_key"
      },
      "widgets_values": [],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 32,
      "type": "ShowText",
      "pos": [
        600.801025390625,
        790.7787475585938
      ],
      "size": [
        435.1482849121094,
        346.5057678222656
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 41
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "title": "final prompt",
      "properties": {
        "cnr_id": "comfyui-show-text",
        "ver": "1.0.2",
        "Node name for S&R": "ShowText"
      },
      "widgets_values": [
        "",
        "literati landscape painting, towering pines with bone structure brushwork, dwarfed scholar figures in Wu Daozi-inspired drapery, minimal facial strokes, cliffside pavilion in dry cun strokes, terraced fields in layered ink wash, recluse’s hut vanishing into mist-cloud technique, negative space over 40%, hemp-fiber strokes on robes, axe-cut texture on hut, azure cliffs, vermilion seals, running-script poetry inscriptions, yinshou seal in Qin-Han style, mineral pigments, high distance perspective, deep distance layering, level distance mist, ink wash textures, fangtou cun randomness, subdued chromatic hierarchy, Yuan-era aesthetic, centered composition, ethereal lighting, traditional Chinese brushwork, misty atmosphere, symbolic spatial order"
      ]
    },
    {
      "id": 31,
      "type": "ai4artsed_openrouter",
      "pos": [
        -502.5132141113281,
        784.4918212890625
      ],
      "size": [
        890.0345458984375,
        858.2985229492188
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "input_prompt",
          "type": "STRING",
          "widget": {
            "name": "input_prompt"
          },
          "link": 42
        },
        {
          "name": "api_key",
          "type": "STRING",
          "widget": {
            "name": "api_key"
          },
          "link": 44
        }
      ],
      "outputs": [
        {
          "name": "output",
          "type": "STRING",
          "links": [
            41,
            43
          ]
        }
      ],
      "properties": {
        "aux_id": "joeriben/ai4artsed_comfyui",
        "ver": "fe64c5c981a6053532151e879437df25061dd945",
        "Node name for S&R": "ai4artsed_openrouter"
      },
      "widgets_values": [
        "",
        "NULL=neutral",
        "Use the input to create a prompt suitable for Stable Diffusion 3.5.\nInstructions:\n1. Select only information that can be rendered visually: entities, their visual properties, spatial configurations, symbolic or narrative roles if they have visual consequences (e.g. pose, gesture, setting, costume).\n2. Ignore non-visual symbolic or abstract relations unless they manifest as visible differences (e.g. \"freedom\" → \"confinement\" becomes \"open field\" → \"prison room\").\n3. Condense the result into a comma-separated prompt with no more than 75 tokens. Use compressed, stylized language typical for SD prompts.\n4. Do not use full sentences. Avoid repetition. Do not include any meta-text or explanation.\n5. Emphasize key compositional and stylistic features if evident (e.g. centered, dramatic lighting, overcast, wide angle, cinematic).\nOutput: Only the resulting prompt as plain text. No table, no explanation, no formatting.\n\nIf the resulting prompt is clearly under 75 tokens, expand it by:\n– adding visually descriptive adjectives (e.g. lighting, texture, motion, color quality)\n– specifying environmental or background elements that imply the mood\n– including camera or compositional hints (e.g. angle, framing, focus)\n– inserting emotional or symbolic indicators only if they have visual impact\n\nDo not pad artificially or repeat. Prioritize meaningful, image-relevant details.",
        "",
        "deepseek/deepseek-chat-v3-0324",
        "enable"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 30,
      "type": "ai4artsed_openrouter",
      "pos": [
        -1021.5064697265625,
        -426.2983703613281
      ],
      "size": [
        480.9454345703125,
        367.0909118652344
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "input_prompt",
          "type": "STRING",
          "widget": {
            "name": "input_prompt"
          },
          "link": 32
        },
        {
          "name": "api_key",
          "type": "STRING",
          "widget": {
            "name": "api_key"
          },
          "link": 37
        }
      ],
      "outputs": [
        {
          "name": "output",
          "type": "STRING",
          "links": [
            33,
            36
          ]
        }
      ],
      "properties": {
        "aux_id": "joeriben/ai4artsed_comfyui",
        "ver": "fe64c5c981a6053532151e879437df25061dd945",
        "Node name for S&R": "ai4artsed_openrouter"
      },
      "widgets_values": [
        "",
        "NULL=neutral",
        "Analyze the image resp. image description and output exactly two separate tables. Do not include any introductory or explanatory text beyond these tables.\nFirst Table: Visually Observable Entities and Relationships\nFormat:\n| Entity 1 | Relation | Entity 2 | Relation Type |\nInstructions:\n1. Identify all visible or implied entities (people, objects, animals, symbols, elements of the environment, etc.).\n2. For each pair of entities, specify a concrete relation that connects them using clear, unambiguous terms (e.g., \"above\", \"next to\", \"inside\", \"wearing\", \"has color\").\n3. Classify each relation into one of the following types:\n- spatial (e.g., above, next to, inside)\n- temporal (e.g., before, after, simultaneous)\n- causal (e.g., causes, enables, prevents)\n- symbolic (e.g., represents, connotes, expresses)\n- narrative (e.g., protagonist of, is acted upon by, interacts with)\n- social (e.g., mother of, enemy of, supports)\n- property (e.g., has color, has gender, has age, shows emotion)\nSecond Table: Inferred or Interpretative Semantic Relations\nFormat:\n| Subject | Inferred Relation | Object / Value | Type | Source |\nInstructions:\n1. Extract higher-level, inferred semantic relations based on visual cues and contextual hints. These relations can include emotional states, narrative context, symbolic meanings, social dynamics, environmental impressions, temporal cues, or attentional focus.\n2. For each inference, specify the relation clearly and classify it using one of the following types: emotional, narrative, symbolic, social, environmental, temporal, attentional, or other.\n3. In the “Source” column, indicate the origin of the inference (e.g., \"visual cue\", \"contextual inference\", \"cultural trope\", \"associative logic\").\n4. Use one row per relation.\nOutput only the two markdown tables in the specified format.",
        "",
        "anthropic/claude-3.7-sonnet:thinking",
        "disable"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 15,
      "type": "ai4artsed_openrouter",
      "pos": [
        -457.1026916503906,
        -357.3642578125
      ],
      "size": [
        781.25,
        1059.449951171875
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "input_prompt",
          "type": "STRING",
          "widget": {
            "name": "input_prompt"
          },
          "link": 36
        },
        {
          "name": "api_key",
          "type": "STRING",
          "widget": {
            "name": "api_key"
          },
          "link": 38
        }
      ],
      "outputs": [
        {
          "name": "output",
          "type": "STRING",
          "links": [
            29,
            42
          ]
        }
      ],
      "title": "ai4artsed_prompt_interception",
      "properties": {
        "aux_id": "joeriben/ai4artsed_comfyui",
        "ver": "fe64c5c981a6053532151e879437df25061dd945",
        "Node name for S&R": "ai4artsed_openrouter"
      },
      "widgets_values": [
        "",
        "1. Detect all entities and visual elements in the source image-description.\n2. Transform each element into its diametrical opposite: female → male, old → young, large → small, red → green, joyful → sorrowful, friendly → hostile, etc. Ensure the inversion is categorical and exhaustive.\n3. Identify all inter-entity relations: spatial (above → below, inside → outside), logical (cause → effect), narrative (protagonist → bystander), and kinship (mother → son or stranger). Invert each relation accordingly.\n4. Reconstruct a coherent image concept using the transformed entities in their reversed relations. Preserve the structural logic of the original while applying full semantic reversal.\n5. Output only the final configuration. Do not include commentary, explanations, or meta-descriptions.",
        "Transform the image-description according to the logic and instructions defined in the input labeled “input_context”.\nThis is not a linguistic translation, but a semantic and structural transformation.\nReconstruct all entities and their relations as specified, ensuring that:\n- Each entity is retained and transformed as instructed.\n- Each relation is inverted or altered in line with the logic of the “Context”.\n- The resulting structure reflects a complete semantic inversion.\nDo not explain your reasoning.\nOutput only the transformed description, either as structured data (if input was structured), or as plain descriptive text (if input was textual).",
        "",
        "anthropic/claude-3.7-sonnet:thinking",
        "enable"
      ],
      "color": "#322",
      "bgcolor": "#533"
    }
  ],
  "links": [
    [
      1,
      4,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      29,
      15,
      0,
      29,
      0,
      "STRING"
    ],
    [
      32,
      26,
      0,
      30,
      0,
      "STRING"
    ],
    [
      33,
      30,
      0,
      28,
      0,
      "STRING"
    ],
    [
      36,
      30,
      0,
      15,
      0,
      "STRING"
    ],
    [
      37,
      11,
      0,
      30,
      1,
      "STRING"
    ],
    [
      38,
      11,
      0,
      15,
      1,
      "STRING"
    ],
    [
      39,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      40,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      41,
      31,
      0,
      32,
      0,
      "STRING"
    ],
    [
      42,
      15,
      0,
      31,
      0,
      "STRING"
    ],
    [
      43,
      31,
      0,
      6,
      1,
      "STRING"
    ],
    [
      44,
      11,
      0,
      31,
      1,
      "STRING"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6209213230591552,
      "offset": [
        2191.6143429287845,
        976.6429461223562
      ]
    }
  },
  "version": 0.4
}
