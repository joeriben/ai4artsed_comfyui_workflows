{"id":"51774992-2cc6-467d-b81d-cbed57895b7f","revision":0,"last_node_id":53,"last_link_id":80,"nodes":[{"id":5,"type":"EmptyLatentImage","pos":[1845.0916748046875,886.107421875],"size":[315,106],"flags":{},"order":0,"mode":0,"inputs":[{"localized_name":"width","name":"width","type":"INT","widget":{"name":"width"},"link":null},{"localized_name":"height","name":"height","type":"INT","widget":{"name":"height"},"link":null},{"localized_name":"batch_size","name":"batch_size","type":"INT","widget":{"name":"batch_size"},"link":null}],"outputs":[{"localized_name":"LATENT","name":"LATENT","type":"LATENT","slot_index":0,"links":[2]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"EmptyLatentImage"},"widgets_values":[1024,1024,1]},{"id":8,"type":"VAEDecode","pos":[1511.0772705078125,901.7804565429688],"size":[210,46],"flags":{},"order":15,"mode":0,"inputs":[{"localized_name":"samples","name":"samples","type":"LATENT","link":7},{"localized_name":"vae","name":"vae","type":"VAE","link":8}],"outputs":[{"localized_name":"IMAGE","name":"IMAGE","type":"IMAGE","slot_index":0,"links":[9]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"VAEDecode"},"widgets_values":[]},{"id":7,"type":"CLIPTextEncode","pos":[1382.3824462890625,1219.0897216796875],"size":[425.27801513671875,180.6060791015625],"flags":{},"order":6,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":5},{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":null}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[6]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"CLIPTextEncode"},"widgets_values":["text, watermark"]},{"id":6,"type":"CLIPTextEncode","pos":[1382.6529541015625,1001.113525390625],"size":[422.84503173828125,164.31304931640625],"flags":{},"order":12,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":3},{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":67}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[4]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"CLIPTextEncode"},"widgets_values":["beautiful scenery nature glass bottle landscape, , purple galaxy bottle,"]},{"id":4,"type":"CheckpointLoaderSimple","pos":[-184.91697692871094,333.4123229980469],"size":[730.3237915039062,114.64132690429688],"flags":{},"order":1,"mode":0,"inputs":[{"localized_name":"ckpt_name","name":"ckpt_name","type":"COMBO","widget":{"name":"ckpt_name"},"link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","slot_index":0,"links":[1]},{"localized_name":"CLIP","name":"CLIP","type":"CLIP","slot_index":1,"links":[3,5]},{"localized_name":"VAE","name":"VAE","type":"VAE","slot_index":2,"links":[8]}],"title":"Choose your model (or leave the preset)","properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["sd3.5_large_fp8_scaled.safetensors"],"color":"#232","bgcolor":"#353"},{"id":3,"type":"KSampler","pos":[1856.083740234375,1077.40966796875],"size":[352.9214782714844,262],"flags":{},"order":14,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":1},{"localized_name":"positive","name":"positive","type":"CONDITIONING","link":4},{"localized_name":"negative","name":"negative","type":"CONDITIONING","link":6},{"localized_name":"latent_image","name":"latent_image","type":"LATENT","link":2},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null},{"localized_name":"steps","name":"steps","type":"INT","widget":{"name":"steps"},"link":null},{"localized_name":"cfg","name":"cfg","type":"FLOAT","widget":{"name":"cfg"},"link":null},{"localized_name":"sampler_name","name":"sampler_name","type":"COMBO","widget":{"name":"sampler_name"},"link":null},{"localized_name":"scheduler","name":"scheduler","type":"COMBO","widget":{"name":"scheduler"},"link":null},{"localized_name":"denoise","name":"denoise","type":"FLOAT","widget":{"name":"denoise"},"link":null}],"outputs":[{"localized_name":"LATENT","name":"LATENT","type":"LATENT","slot_index":0,"links":[7]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"KSampler"},"widgets_values":[747379373046437,"randomize",25,7,"euler","normal",1]},{"id":28,"type":"PrimitiveString","pos":[-201.56451416015625,210.54537963867188],"size":[728.9432373046875,66.43585205078125],"flags":{},"order":2,"mode":0,"inputs":[{"localized_name":"value","name":"value","type":"STRING","widget":{"name":"value"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[66]}],"title":"Provide a context: neutral","properties":{"cnr_id":"comfy-core","ver":"0.3.27","Node name for S&R":"PrimitiveString"},"widgets_values":["150 tokens maximum"],"color":"#232","bgcolor":"#353"},{"id":48,"type":"ai4artsed_openrouter","pos":[-52.2102165222168,-848.3853759765625],"size":[535.7310791015625,437.2164611816406],"flags":{},"order":7,"mode":0,"inputs":[{"localized_name":"input_prompt","name":"input_prompt","type":"STRING","link":72},{"localized_name":"input_context","name":"input_context","type":"STRING","widget":{"name":"input_context"},"link":null},{"localized_name":"style_prompt","name":"style_prompt","type":"STRING","widget":{"name":"style_prompt"},"link":null},{"localized_name":"api_key","name":"api_key","type":"STRING","widget":{"name":"api_key"},"link":77},{"localized_name":"model","name":"model","type":"COMBO","widget":{"name":"model"},"link":null},{"localized_name":"debug","name":"debug","type":"COMBO","widget":{"name":"debug"},"link":null}],"outputs":[{"localized_name":"output","name":"output","type":"STRING","links":[73,75]}],"properties":{"aux_id":"joeriben/ai4artsed_comfyui","ver":"deb559d62ef3e4e11766b726b4d3d453b03b56e0","Node name for S&R":"ai4artsed_openrouter"},"widgets_values":["Input CONTEXT here","Translate the input into english.\nAnalyze the input and output exactly two separate tables. Do not include any introductory or explanatory text beyond these tables.\nFirst Table: Visually Observable Entities and Relationships\nFormat:\n| Entity 1 | Relation | Entity 2 | Relation Type |\nInstructions:\n1. Identify all visible or implied entities (people, objects, animals, symbols, elements of the environment, etc.).\n2. For each pair of entities, specify a concrete relation that connects them using clear, unambiguous terms (e.g., \"above\", \"next to\", \"inside\", \"wearing\", \"has color\").\n3. Classify each relation into one of the following types:\n- spatial (e.g., above, next to, inside)\n- temporal (e.g., before, after, simultaneous)\n- causal (e.g., causes, enables, prevents)\n- symbolic (e.g., represents, connotes, expresses)\n- narrative (e.g., protagonist of, is acted upon by, interacts with)\n- social (e.g., mother of, enemy of, supports)\n- property (e.g., has color, has gender, has age, shows emotion)\nSecond Table: Inferred or Interpretative Semantic Relations\nFormat:\n| Subject | Inferred Relation | Object / Value | Type | Source |\nInstructions:\n1. Extract higher-level, inferred semantic relations based on visual cues and contextual hints. These relations can include emotional states, narrative context, symbolic meanings, social dynamics, environmental impressions, temporal cues, or attentional focus.\n2. For each inference, specify the relation clearly and classify it using one of the following types: emotional, narrative, symbolic, social, environmental, temporal, attentional, or other.\n3. In the “Source” column, indicate the origin of the inference (e.g., \"visual cue\", \"contextual inference\", \"cultural trope\", \"associative logic\").\n4. Use one row per relation.\nOutput only the two markdown tables in the specified format.","","deepseek/deepseek-r1","enable"],"color":"#322","bgcolor":"#533"},{"id":53,"type":"PreviewAny","pos":[1424.5552978515625,270.13037109375],"size":[331.78857421875,412.4862365722656],"flags":{},"order":13,"mode":0,"inputs":[{"localized_name":"source","name":"source","type":"*","link":80}],"outputs":[],"title":"final prompt","properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"PreviewAny"},"widgets_values":[]},{"id":52,"type":"ai4artsed_openrouter_key","pos":[-467.19384765625,-431.07464599609375],"size":[283.79132080078125,26],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[77,78,79]}],"properties":{"aux_id":"joeriben/ai4artsed_comfyui","ver":"deb559d62ef3e4e11766b726b4d3d453b03b56e0","Node name for S&R":"ai4artsed_openrouter_key"},"widgets_values":[],"color":"#322","bgcolor":"#533"},{"id":47,"type":"PrimitiveString","pos":[-31.126121520996094,-1042.4947509765625],"size":[536.6666870117188,94.46724700927734],"flags":{},"order":4,"mode":0,"inputs":[{"localized_name":"value","name":"value","type":"STRING","widget":{"name":"value"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[72]}],"title":"ai4artsed_text_prompt","properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"PrimitiveString"},"widgets_values":["ein blauer Hund auf einem kreisrunden roten Teppich im Wald"],"color":"#232","bgcolor":"#353"},{"id":9,"type":"SaveImage","pos":[1945.4708251953125,-771.6322021484375],"size":[782.6429443359375,895.6958618164062],"flags":{},"order":16,"mode":0,"inputs":[{"localized_name":"images","name":"images","type":"IMAGE","link":9},{"localized_name":"filename_prefix","name":"filename_prefix","type":"STRING","widget":{"name":"filename_prefix"},"link":null}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.27"},"widgets_values":["ComfyUI"]},{"id":40,"type":"ai4artsed_openrouter","pos":[591.6130981445312,-703.2437744140625],"size":[571.1720581054688,460.5925598144531],"flags":{},"order":8,"mode":0,"inputs":[{"localized_name":"input_prompt","name":"input_prompt","type":"STRING","link":73},{"localized_name":"input_context","name":"input_context","type":"STRING","widget":{"name":"input_context"},"link":74},{"localized_name":"style_prompt","name":"style_prompt","type":"STRING","widget":{"name":"style_prompt"},"link":null},{"localized_name":"api_key","name":"api_key","type":"STRING","widget":{"name":"api_key"},"link":78},{"localized_name":"model","name":"model","type":"COMBO","widget":{"name":"model"},"link":null},{"localized_name":"debug","name":"debug","type":"COMBO","widget":{"name":"debug"},"link":null}],"outputs":[{"localized_name":"output","name":"output","type":"STRING","links":[65,76]}],"properties":{"aux_id":"joeriben/ai4artsed_comfyui","ver":"0464d155e31fa8ab956aa907e233794cfb04bc70","Node name for S&R":"ai4artsed_openrouter"},"widgets_values":["","Transform the image description according to the logic and instructions defined in the input labeled “input_context”.\nThis is not a linguistic translation, but a semantic and structural transformation.\nReconstruct all entities and their relations as specified, ensuring that:\n- Each entity is retained and transformed as instructed.\n- Each relation is inverted or altered in line with the logic of the “Context”.\n- The resulting structure reflects a complete semantic inversion.\nDo not explain your reasoning.\nOutput only the transformed description, either as structured data (if input was structured), or as plain descriptive text (if input was textual).","","deepseek/deepseek-r1","enable"],"color":"#322","bgcolor":"#533"},{"id":49,"type":"PrimitiveStringMultiline","pos":[-20.755802154541016,-323.97607421875],"size":[546.6666870117188,424.3874816894531],"flags":{},"order":5,"mode":0,"inputs":[{"localized_name":"value","name":"value","type":"STRING","widget":{"name":"value"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[74]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"PrimitiveStringMultiline"},"widgets_values":["1. Detect all entities and visual elements in the source image.\n2. Transform each element into its diametrical opposite: female → male, old → young, large → small, red → green, joyful → sorrowful, friendly → hostile, etc. Ensure the inversion is categorical and exhaustive.\n3. Identify all inter-entity relations: spatial (above → below, inside → outside), logical (cause → effect), narrative (protagonist → bystander), and kinship (mother → son or stranger). Invert each relation accordingly.\n- VERY IMPORTANT: AVOID REVERSION BY DOUBLE NEGATION (RESULTING IN THE ORIGINAL RELATION) AT ALL COSTS!\n4. Reconstruct a coherent image concept using the transformed entities in their reversed relations. Preserve the structural logic of the original while applying full semantic reversal.\n5. Output only the final configuration. Do not include commentary, explanations, or meta-descriptions."],"color":"#322","bgcolor":"#533"},{"id":51,"type":"PreviewAny","pos":[1212.29833984375,-1053.92041015625],"size":[656.2184448242188,525.0900268554688],"flags":{},"order":11,"mode":0,"inputs":[{"localized_name":"source","name":"source","type":"*","link":76}],"outputs":[],"title":"complete inversion","properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"PreviewAny"},"widgets_values":[]},{"id":50,"type":"PreviewAny","pos":[561.50634765625,-1156.2978515625],"size":[539.4837036132812,406.47247314453125],"flags":{},"order":9,"mode":0,"inputs":[{"localized_name":"source","name":"source","type":"*","link":75}],"outputs":[],"title":"logical analysis of the input","properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"PreviewAny"},"widgets_values":[]},{"id":42,"type":"ai4artsed_openrouter","pos":[668.3900146484375,-74.93212127685547],"size":[668.3419189453125,481.2996520996094],"flags":{},"order":10,"mode":0,"inputs":[{"localized_name":"input_prompt","name":"input_prompt","type":"STRING","link":65},{"localized_name":"input_context","name":"input_context","type":"STRING","widget":{"name":"input_context"},"link":66},{"localized_name":"style_prompt","name":"style_prompt","type":"STRING","widget":{"name":"style_prompt"},"link":null},{"localized_name":"api_key","name":"api_key","type":"STRING","widget":{"name":"api_key"},"link":79},{"localized_name":"model","name":"model","type":"COMBO","widget":{"name":"model"},"link":null},{"localized_name":"debug","name":"debug","type":"COMBO","widget":{"name":"debug"},"link":null}],"outputs":[{"localized_name":"output","name":"output","type":"STRING","links":[67,80]}],"properties":{"aux_id":"joeriben/ai4artsed_comfyui","ver":"0464d155e31fa8ab956aa907e233794cfb04bc70","Node name for S&R":"ai4artsed_openrouter"},"widgets_values":["","Your Task: CLIP Optimization for clip_l/g (Stable Diffusion 3.5)\n\nOUTPUT THE PURE RESULTING PROMPT ONLY!\n\nYou will receive a user prompt for image generation. Restructure it ONLY by reordering, for CLIP models that strongly weight early tokens and truncate at 75 tokens.\n\nNEVER INCLUDE ANY META-INFORMATION SUCH AS THE NAMES OF THE DIMENSIONS BELOW OR THE TOKEN COUNT\n\nCLIP-Specific Rules\n\nAbsolute token limit: 75 (recommended ≤70)\n\nGeneral information:\nALWAYS EXTRAKT ONLY THE INFORMATION THAT IS VISUALLY RELEVANT. YOUR PROMPT WILL RESULT IN A COMMA_SEPARATED SERIES OF GROUOPED TOKENS; BARELY EVER CONNTECTED BY VERBS OR CONJUNCTIONS.\n\nBUT YOU WILL REORDER ALL THESE TOKENS ACCORDING TO THE FOLLOWING ORDER:\n\nEarly tokens = critical: The first 20–30 tokens largely determine the image\nMinimize Attributes: CLIP struggles with complex attributes – keep them short\nClear, direct terms: CLIP prefers concrete nouns and simple adjectives\nDo not alter the input text – no substitutions, paraphrasing, or lexical replacements allowed\n\n\nYOUR OUTPUT:\nCore Motif (15–20 tokens, 25–30%):\nPlace the main subject FIRST\nUse the exact wording provided in the original prompt\nEMPTY LINE\nAction (10–15 tokens, 15–20%):\nFollows the subject directly for strong subject-action linkage\nPrefer simple verb phrases; maintain exact original wording\nEMPTY LINE\nStyle/Medium (10–15 tokens, 15–20%):\nPlace early in the prompt for maximum impact on CLIP\nTypical examples: “oil painting”, “photography”, “3D render”\nUse only if present in the original prompt\nEMPTY LINE\nContext (10–15 tokens, 15–20%):\nLocation or setting, compressed\nReorder only; do not paraphrase\nEMPTY LINE\nAttributes (5–10 tokens, 10–15%):\nMinimize; include only if essential\nNo changes to wording – do not replace or reformulate\nEMPTY LINETechnical Aspects (0–5 tokens, 0–7%):\nInclude only if tokens remain and if originally present","","google/gemini-2.5-pro-preview","enable"],"color":"#322","bgcolor":"#533"}],"links":[[1,4,0,3,0,"MODEL"],[2,5,0,3,3,"LATENT"],[3,4,1,6,0,"CLIP"],[4,6,0,3,1,"CONDITIONING"],[5,4,1,7,0,"CLIP"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[8,4,2,8,1,"VAE"],[9,8,0,9,0,"IMAGE"],[65,40,0,42,0,"STRING"],[66,28,0,42,1,"STRING"],[67,42,0,6,1,"STRING"],[72,47,0,48,0,"STRING"],[73,48,0,40,0,"STRING"],[74,49,0,40,1,"STRING"],[75,48,0,50,0,"*"],[76,40,0,51,0,"*"],[77,52,0,48,3,"STRING"],[78,52,0,40,3,"STRING"],[79,52,0,42,3,"STRING"],[80,42,0,53,0,"*"]],"groups":[],"config":{},"extra":{"ds":{"scale":0.6727499949325624,"offset":[-108.91786508361133,1010.353665721686]}},"version":0.4}